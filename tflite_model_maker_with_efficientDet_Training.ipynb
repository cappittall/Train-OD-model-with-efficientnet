{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install Miniconda and create a virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.9.2-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.9.2-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-py37_4.9.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update Conda\n",
        "!conda update -n base -c defaults conda -y\n",
        "\n",
        "# Create a Python 3.9 environment\n",
        "!conda create --name py39_environment python=3.9 -y\n",
        "\n",
        "# Initialize shell for Conda\n",
        "!conda init bash\n",
        "\n",
        "# Activate the environment and check Python version\n",
        "!source activate py39_environment && python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T2jd1LLHr5O",
        "outputId": "f43bcb4e-16db-4f83-99a4-3009e3a5b7dd"
      },
      "outputs": [],
      "source": [
        "!source activate py39_environment && python --version\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install tflite_model_maker\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install -q pycocotools\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install opencv-python-headless\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip uninstall -y tensorflow && pip install -q tensorflow==2.8.0\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install ipykernel\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install --upgrade numba llvmlite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXdz8hA7MqVN"
      },
      "outputs": [],
      "source": [
        "# LOAD DATASET\n",
        "# # load dataset from roboflow as pascal voc format \n",
        "!curl -L \"https://app.roboflow.com/ds/S......Ab?key=XS3minlymZ\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzt0EPAJNXGW"
      },
      "outputs": [],
      "source": [
        "# PREPARE DATASET\n",
        "!mkdir -p dataset/images\n",
        "!mkdir -p dataset/annotations\n",
        "\n",
        "!mv train/*.xml dataset/annotations/\n",
        "!mv train/*.jpg dataset/images/\n",
        "\n",
        "!mv test/*.xml dataset/annotations/\n",
        "!mv test/*.jpg dataset/images/\n",
        "\n",
        "!mv valid/*.xml dataset/annotations/\n",
        "!mv valid/*.jpg dataset/images/\n",
        "!rm -r test\n",
        "!rm -r train\n",
        "!rm -r valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a training Python script in order to train with Efficient model using tflite_model_maker\n",
        "## adjust the pretrained model and epochs ( valid efficientdet_lite2 model and epochs 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yYZ6PWfH891",
        "outputId": "c91d9878-d951-4bc6-887c-1f79fb1f1052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting my_script.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_script.py\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.object = object\n",
        "np.bool = bool\n",
        "np.complex = complex\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "use_custom_dataset = True\n",
        "dataset_is_split = False\n",
        "\n",
        "if use_custom_dataset:\n",
        "\n",
        "  # The ZIP file you uploaded:\n",
        "  #!unzip dataset.zip\n",
        "\n",
        "  # Your labels map as a dictionary (zero is reserved):\n",
        "  label_map = {1: 'YM'}\n",
        "  print(label_map)\n",
        "\n",
        "  if dataset_is_split:\n",
        "    # If your dataset is already split, specify each path:\n",
        "    train_images_dir = 'dataset/train/images'\n",
        "    train_annotations_dir = 'dataset/train/annotations'\n",
        "    val_images_dir = 'dataset/validation/images'\n",
        "    val_annotations_dir = 'dataset/validation/annotations'\n",
        "    test_images_dir = 'dataset/test/images'\n",
        "    test_annotations_dir = 'dataset/test/annotations'\n",
        "  else:\n",
        "    # If it's NOT split yet, specify the path to all images and annotations\n",
        "    images_in = 'dataset/images'\n",
        "    annotations_in = 'dataset/annotations'\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n",
        "  \"\"\"Splits a directory of sorted images/annotations into training, validation, and test sets.\n",
        "\n",
        "  Args:\n",
        "    images_path: Path to the directory with your images (JPGs).\n",
        "    annotations_path: Path to a directory with your VOC XML annotation files,\n",
        "      with filenames corresponding to image filenames. This may be the same path\n",
        "      used for images_path.\n",
        "    val_split: Fraction of data to reserve for validation (float between 0 and 1).\n",
        "    test_split: Fraction of data to reserve for test (float between 0 and 1).\n",
        "  Returns:\n",
        "    The paths for the split images/annotations (train_dir, val_dir, test_dir)\n",
        "  \"\"\"\n",
        "  _, dirs, _ = next(os.walk(images_path))\n",
        "\n",
        "  train_dir = os.path.join(out_path, 'train')\n",
        "  val_dir = os.path.join(out_path, 'validation')\n",
        "  test_dir = os.path.join(out_path, 'test')\n",
        "\n",
        "  IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images')\n",
        "  IMAGES_VAL_DIR = os.path.join(val_dir, 'images')\n",
        "  IMAGES_TEST_DIR = os.path.join(test_dir, 'images')\n",
        "  os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations')\n",
        "  ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations')\n",
        "  ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations')\n",
        "  os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  # Get all filenames for this dir, filtered by filetype\n",
        "  filenames = os.listdir(os.path.join(images_path))\n",
        "  filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n",
        "  # Shuffle the files, deterministically\n",
        "  filenames.sort()\n",
        "  random.seed(42)\n",
        "  random.shuffle(filenames)\n",
        "  # Get exact number of images for validation and test; the rest is for training\n",
        "  val_count = int(len(filenames) * val_split)\n",
        "  test_count = int(len(filenames) * test_split)\n",
        "  for i, file in enumerate(filenames):\n",
        "    source_dir, filename = os.path.split(file)\n",
        "    annot_file = os.path.join(annotations_path, filename.replace(\".jpg\", \".xml\"))\n",
        "    if i < val_count:\n",
        "      shutil.copy(file, IMAGES_VAL_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_VAL_DIR)\n",
        "    elif i < val_count + test_count:\n",
        "      shutil.copy(file, IMAGES_TEST_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TEST_DIR)\n",
        "    else:\n",
        "      shutil.copy(file, IMAGES_TRAIN_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n",
        "  return (train_dir, val_dir, test_dir)\n",
        "\n",
        "# We need to instantiate a separate DataLoader for each split dataset\n",
        "if use_custom_dataset:\n",
        "  if dataset_is_split:\n",
        "    train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        train_images_dir, train_annotations_dir, label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        val_images_dir, val_annotations_dir, label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        test_images_dir, test_annotations_dir, label_map=label_map)\n",
        "  else:\n",
        "    train_dir, val_dir, test_dir = split_dataset(images_in, annotations_in,\n",
        "                                                 val_split=0.2, test_split=0.2,\n",
        "                                                 out_path='split-dataset')\n",
        "    train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(train_dir, 'images'),\n",
        "        os.path.join(train_dir, 'annotations'), label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(val_dir, 'images'),\n",
        "        os.path.join(val_dir, 'annotations'), label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(test_dir, 'images'),\n",
        "        os.path.join(test_dir, 'annotations'), label_map=label_map)\n",
        "\n",
        "  print(f'train count: {len(train_data)}')\n",
        "  print(f'validation count: {len(validation_data)}')\n",
        "  print(f'test count: {len(test_data)}')\n",
        "\n",
        "\n",
        "spec = model_spec.get('efficientdet_lite2')\n",
        "\n",
        "model = object_detector.create(train_data=train_data,\n",
        "                               model_spec=spec,\n",
        "                               validation_data=validation_data,\n",
        "                               epochs=100,\n",
        "                               batch_size=10,\n",
        "                               train_whole_model=True)\n",
        "\n",
        "\n",
        "TFLITE_FILENAME = 'my_tflite_model.tflite'\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "\n",
        "model.export(export_dir='.', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
        "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])\n",
        "\n",
        "\n",
        "model.evaluate(test_data)\n",
        "\n",
        "model.evaluate_tflite(TFLITE_FILENAME, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run the script with proper environment (created before) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXOiK3xMpPb",
        "outputId": "bb4618e1-f2f6-4d92-8d74-5b4dea3d3e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/envs/py39_environment/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/py39_environment/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "{1: 'YM'}\n",
            "train count: 1090\n",
            "validation count: 362\n",
            "test count: 362\n",
            "2023-10-01 13:03:19.621004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:19.699240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:19.699687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:19.700609: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-01 13:03:19.700919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:19.701256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:19.701595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:20.594693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:20.595210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:20.595600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 13:03:20.595796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-10-01 13:03:20.595861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13786 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-10-01 13:04:20.905904: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8900\n",
            "109/109 [==============================] - 134s 761ms/step - det_loss: 2.0116 - cls_loss: 1.0288 - box_loss: 0.0197 - reg_l2_loss: 0.0761 - loss: 2.0877 - learning_rate: 0.0102 - gradient_norm: 6.1943 - val_det_loss: 2.6291 - val_cls_loss: 1.0502 - val_box_loss: 0.0316 - val_reg_l2_loss: 0.0767 - val_loss: 2.7058\n",
            "2023-10-01 13:05:52.805022: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2023-10-01 13:06:35.167162: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n",
            "2023-10-01 13:06:50.153484: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2023-10-01 13:06:50.153536: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "2023-10-01 13:06:50.158212: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpcgwxlpgj\n",
            "2023-10-01 13:06:50.326732: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2023-10-01 13:06:50.326795: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpcgwxlpgj\n",
            "2023-10-01 13:06:50.921908: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2023-10-01 13:06:54.051071: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpcgwxlpgj\n",
            "2023-10-01 13:06:55.318119: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 5159918 microseconds.\n",
            "2023-10-01 13:06:57.559574: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-10-01 13:07:02.681569: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 6.066 G  ops, equivalently 3.033 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 6.066 G  ops, equivalently 3.033 G  MACs\n"
          ]
        }
      ],
      "source": [
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && python my_script.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create edgetpu version of model for edge devices like coral development kit (coral.ai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j499kiW4SbX",
        "outputId": "26e1c563-9447-4354-d2a2-cdf913d1cbb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  15316      0 --:--:-- --:--:-- --:--:-- 15369\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [517 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:7 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:7 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,144 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,165 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,016 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,287 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,264 kB]\n",
            "Hit:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:21 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,128 kB]\n",
            "Get:23 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [37.7 kB]\n",
            "Fetched 10.2 MB in 8s (1,316 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 0s (27.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ZAJhSe4tH3",
        "outputId": "786d0fe4-156d-475d-99fb-e85065fde1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Searching for valid delegate with step 1\n",
            "Try to compile segment with 357 ops\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 19550 ms.\n",
            "\n",
            "Input model: x-ray-effi0-v4.tflite\n",
            "Input size: 7.05MiB\n",
            "Output model: x-ray-effi0-v4_edgetpu.tflite\n",
            "Output size: 9.74MiB\n",
            "On-chip memory used for caching model parameters: 7.14MiB\n",
            "On-chip memory remaining for caching model parameters: 1.25KiB\n",
            "Off-chip memory used for streaming uncached model parameters: 228.88KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 357\n",
            "Operation log: x-ray-effi0-v4_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 354\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "NUMBER_OF_TPUS =  1\n",
        "TFLITE_FILENAME = 'x-ray-effi0-v4.tflite'\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "!edgetpu_compiler $TFLITE_FILENAME -d --num_segments=$NUMBER_OF_TPUS"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
